# ğŸ“Š PySpark Aggregate Functions

---

In PySpark, **aggregation functions** help summarize or compute statistics on data.  
They are often used with **`groupBy()`**, **`agg()`**, or **`select()`**.

---

## ğŸ”¹ **Common Aggregate Functions**

| ğŸ›  Function | ğŸ“– Description |
|-------------|---------------|
| `count()` | ğŸ”¢ Count number of rows |
| `sum()` | â• Sum of values |
| `avg()` | ğŸ“ Average value |
| `max()` | ğŸ”¼ Maximum value |
| `min()` | ğŸ”½ Minimum value |
| `first()` | ğŸ¯ First value |
| `last()` | ğŸ¯ Last value |
| `collect_list()` | ğŸ“ All values as a list (with duplicates) |
| `collect_set()` | ğŸ“ All unique values as a set |

---

## ğŸ“ **Syntax**
```python
from pyspark.sql import functions as F

df.groupBy(column_names).agg(aggregation_expressions)
````

---

## ğŸ“‚ **Sample Data**

```python
from pyspark.sql import SparkSession
from pyspark.sql import functions as F

spark = SparkSession.builder.appName("Aggregate Example").getOrCreate()

data = [
    ("James", "Sales", 3000),
    ("Michael", "Sales", 4600),
    ("Robert", "Sales", 4100),
    ("Maria", "Finance", 3000),
    ("Raman", "Finance", 3000),
    ("Scott", "Finance", 3300),
    ("Jen", "Finance", 3900),
    ("Jeff", "Marketing", 3000),
    ("Kumar", "Marketing", 2000)
]
columns = ["name", "dept", "salary"]

df = spark.createDataFrame(data, columns)
```

---

## 1ï¸âƒ£ **Group By with Single Aggregation**

```python
df.groupBy("dept").agg(
    F.sum("salary").alias("ğŸ’° total_salary")
).show()
```

---

## 2ï¸âƒ£ **Group By with Multiple Aggregations**

```python
df.groupBy("dept").agg(
    F.sum("salary").alias("ğŸ’° total_salary"),
    F.avg("salary").alias("ğŸ“ avg_salary"),
    F.max("salary").alias("ğŸ”¼ max_salary"),
    F.min("salary").alias("ğŸ”½ min_salary"),
    F.count("salary").alias("ğŸ‘¥ employee_count")
).show()
```

---

## 3ï¸âƒ£ **Global Aggregation (Without Grouping)**

```python
df.agg(
    F.sum("salary").alias("ğŸ’° total_salary"),
    F.avg("salary").alias("ğŸ“ avg_salary")
).show()
```

---

## 4ï¸âƒ£ **Count Distinct Values**

```python
df.groupBy("dept").agg(
    F.countDistinct("salary").alias("ğŸ”¢ distinct_salaries")
).show()
```

---

## 5ï¸âƒ£ **Collect List & Set**

```python
df.groupBy("dept").agg(
    F.collect_list("name").alias("ğŸ“ employee_list"),
    F.collect_set("name").alias("ğŸ—‚ unique_employee_set")
).show(truncate=False)
```

---

## 6ï¸âƒ£ **Multiple Columns in Group By**

```python
df.groupBy("dept", "salary").count().show()
```

---

ğŸ’¡ **Notes:**

* **`groupBy()`** groups rows with the same value in one or more columns.
* **`agg()`** can run multiple aggregation functions in one call.
* Use **`select()`** for aggregation without grouping (returns a single row unless a group is specified).

```

I can also prepare a **single compact table output** showing sum, avg, min, max, and count for each department side-by-side with icons, so itâ€™s visually easy to compare.
```
